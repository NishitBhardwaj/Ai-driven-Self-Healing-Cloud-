name: CD Pipeline

on:
  push:
    branches: [ main ]
    tags:
      - 'v*'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production
      aws_region:
        description: 'AWS Region (overrides secret)'
        required: false
        default: ''
        type: choice
        options:
          - us-east-1
          - us-west-2
          - ap-south-1
          - ca-central-1
          - eu-west-1
          - eu-central-1

env:
  REGISTRY: ghcr.io
  IMAGE_PREFIX: ${{ github.repository_owner }}/ai-cloud
  KUBERNETES_NAMESPACE: ai-cloud-${{ github.event.inputs.environment || 'staging' }}

jobs:
  # Install Monitoring CRDs
  install-monitoring-crds:
    name: Install Monitoring CRDs (ServiceMonitor / Prometheus Operator)
    runs-on: ubuntu-latest
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Configure kubectl for EKS
        run: |
          aws eks update-kubeconfig \
            --name "${{ secrets.EKS_CLUSTER_NAME }}" \
            --region "${{ secrets.AWS_REGION }}"

      - name: Check if ServiceMonitor CRD exists
        id: crd_check
        run: |
          if kubectl get crd servicemonitors.monitoring.coreos.com >/dev/null 2>&1; then
            echo "crd_exists=true" >> $GITHUB_OUTPUT
          else
            echo "crd_exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Install ServiceMonitor CRDs if missing
        if: steps.crd_check.outputs.crd_exists == 'false'
        run: |
          echo "Installing Prometheus Operator CRDs..."
          kubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/main/example/prometheus-operator-crd/monitoring.coreos.com_servicemonitors.yaml
          kubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/main/example/prometheus-operator-crd/monitoring.coreos.com_podmonitors.yaml
          kubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/main/example/prometheus-operator-crd/monitoring.coreos.com_prometheuses.yaml
          kubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/main/example/prometheus-operator-crd/monitoring.coreos.com_alertmanagers.yaml
          echo "CRDs installed successfully."

  # Deploy to Kubernetes
  deploy:
    needs: [install-monitoring-crds]
    name: Deploy to Kubernetes
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment || 'staging' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Resolve AWS Region
        run: |
          # Prefer workflow input if provided, otherwise use secret
          INPUT_REGION='${{ github.event.inputs.aws_region }}'
          SECRET_REGION='${{ secrets.AWS_REGION }}'
          if [ -n "$INPUT_REGION" ]; then
            echo "Using region from workflow input: $INPUT_REGION"
            echo "AWS_REGION=$INPUT_REGION" >> $GITHUB_ENV
          else
            echo "Using region from secrets: $SECRET_REGION"
            echo "AWS_REGION=$SECRET_REGION" >> $GITHUB_ENV
          fi

      - name: Set up kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'

      - name: Set up Helm
        uses: azure/setup-helm@v3
        with:
          version: 'latest'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Who am I (AWS identity)?
        run: aws sts get-caller-identity

      - name: Debug EKS vars (safe)
        run: |
          CLUSTER_NAME='${{ secrets.EKS_CLUSTER_NAME }}'
          REGION='${{ env.AWS_REGION }}'
          echo "Cluster name length: ${#CLUSTER_NAME}"
          echo "Region length: ${#REGION}"

      - name: Configure kubectl for EKS
        run: |
          set -euo pipefail
          set -x
          echo "Configuring kubectl for EKS cluster..."
          aws eks update-kubeconfig \
            --name "${{ secrets.EKS_CLUSTER_NAME }}" \
            --region "${{ env.AWS_REGION }}"

      - name: Test cluster access
        run: |
          set -e
          kubectl cluster-info
          kubectl get namespaces --no-headers || true


      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Create namespace
        run: |
          kubectl create namespace ${{ env.KUBERNETES_NAMESPACE }} --dry-run=client -o yaml | kubectl apply -f -

      - name: Deploy with Helm
        run: |
          helm upgrade --install ai-cloud \
            kubernetes/helm/ai-cloud \
            --namespace ${{ env.KUBERNETES_NAMESPACE }} \
            --set image.registry=${{ env.REGISTRY }} \
            --set image.prefix=${{ env.IMAGE_PREFIX }} \
            --set image.tag=${{ github.sha }} \
            --set environment=${{ github.event.inputs.environment || 'staging' }} \
            --wait \
            --timeout 10m

      - name: Verify deployment
        run: |
          kubectl rollout status deployment/ai-cloud-self-healing -n ${{ env.KUBERNETES_NAMESPACE }} --timeout=5m
          kubectl rollout status deployment/ai-cloud-scaling -n ${{ env.KUBERNETES_NAMESPACE }} --timeout=5m
          kubectl rollout status deployment/ai-cloud-task-solving -n ${{ env.KUBERNETES_NAMESPACE }} --timeout=5m

      - name: Run smoke tests
        run: |
          # Wait for services to be ready
          sleep 30
          
          # Test health endpoints
          kubectl run -it --rm test-client --image=curlimages/curl --restart=Never -- \
            curl -f http://ai-cloud-self-healing:8080/health || exit 1
          
          kubectl run -it --rm test-client --image=curlimages/curl --restart=Never -- \
            curl -f http://ai-cloud-scaling:8080/health || exit 1

  # Rollback on failure
  rollback:
    name: Rollback on Failure
    runs-on: ubuntu-latest
    needs: [deploy]
    if: failure()
    env:
      KUBERNETES_NAMESPACE: ai-cloud-${{ github.event.inputs.environment || 'staging' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Resolve AWS Region
        run: |
          # Prefer workflow input if provided, otherwise use secret
          INPUT_REGION='${{ github.event.inputs.aws_region }}'
          SECRET_REGION='${{ secrets.AWS_REGION }}'
          if [ -n "$INPUT_REGION" ]; then
            echo "Using region from workflow input: $INPUT_REGION"
            echo "AWS_REGION=$INPUT_REGION" >> $GITHUB_ENV
          else
            echo "Using region from secrets: $SECRET_REGION"
            echo "AWS_REGION=$SECRET_REGION" >> $GITHUB_ENV
          fi

      - name: Set up kubectl
        uses: azure/setup-kubectl@v3

      - name: Set up Helm
        uses: azure/setup-helm@v3
        with:
          version: 'latest'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Configure kubectl for EKS (rollback)
        run: |
          set -euo pipefail
          set -x
          echo "Configuring kubectl for EKS cluster (rollback)..."
          aws eks update-kubeconfig \
            --name "${{ secrets.EKS_CLUSTER_NAME }}" \
            --region "${{ env.AWS_REGION }}"

      - name: Test cluster access
        run: |
          set -e
          kubectl cluster-info
          kubectl get namespaces --no-headers || true

      - name: Rollback Helm release
        run: |
          helm rollback ai-cloud -n ${{ env.KUBERNETES_NAMESPACE }} || echo "Rollback failed or no previous release"

      - name: Notify team
        if: ${{ secrets.SLACK_WEBHOOK_URL != '' }}
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          text: 'Deployment failed and was rolled back'
          webhook_url: ${{ secrets.SLACK_WEBHOOK_URL }}
        continue-on-error: true

