# Logstash Configuration for Agent Log Ingestion
# This configuration filters, parses, and routes logs from all agents to Elasticsearch

input {
  # TCP input for Go agents
  tcp {
    port => 5000
    codec => json_lines
    type => "agent_log"
  }
  
  # UDP input for high-volume logs
  udp {
    port => 5001
    codec => json
    type => "agent_log"
  }
  
  # HTTP input for REST API logs
  http {
    port => 8080
    codec => json
    type => "http_log"
  }
  
  # File input for file-based logs (fallback)
  file {
    path => "/var/log/agents/*.log"
    start_position => "beginning"
    codec => json_lines
    type => "file_log"
    sincedb_path => "/var/lib/logstash/sincedb"
  }
}

filter {
  # Parse agent logs
  if [type] == "agent_log" {
    # Extract agent information
    if [agent_id] {
      mutate {
        add_field => { "[@metadata][agent_id]" => "%{agent_id}" }
      }
    }
    
    if [agent_name] {
      mutate {
        add_field => { "[@metadata][agent_name]" => "%{agent_name}" }
      }
    }
    
    # Parse timestamp
    if [timestamp] {
      date {
        match => [ "timestamp", "ISO8601", "yyyy-MM-dd'T'HH:mm:ss.SSSZ" ]
        target => "@timestamp"
      }
    }
    
    # Parse action logs
    if [action] {
      mutate {
        add_field => { "[@metadata][action_type]" => "%{action}" }
      }
    }
    
    # Parse explanation logs
    if [explanation] {
      mutate {
        add_field => { "[@metadata][has_explanation]" => "true" }
      }
    }
    
    # Parse confidence level
    if [confidence] {
      mutate {
        convert => { "confidence" => "float" }
      }
    }
    
    # Parse error logs
    if [error] {
      mutate {
        add_field => { "[@metadata][log_type]" => "error" }
      }
    } else if [action] {
      mutate {
        add_field => { "[@metadata][log_type]" => "action" }
      }
    } else {
      mutate {
        add_field => { "[@metadata][log_type]" => "info" }
      }
    }
    
    # Parse mode (auto/manual)
    if [mode] {
      mutate {
        add_field => { "[@metadata][decision_mode]" => "%{mode}" }
      }
    }
    
    # Add common fields
    mutate {
      add_field => { 
        "log_source" => "agent"
        "environment" => "${ENVIRONMENT:development}"
      }
    }
  }
  
  # Parse HTTP logs
  if [type] == "http_log" {
    grok {
      match => { "message" => "%{IPORHOST:client_ip} - - \[%{HTTPDATE:timestamp}\] \"%{WORD:method} %{URIPATH:path} HTTP/%{NUMBER:http_version}\" %{NUMBER:status_code} %{NUMBER:response_time}" }
    }
    
    date {
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
      target => "@timestamp"
    }
  }
  
  # Parse file logs
  if [type] == "file_log" {
    json {
      source => "message"
    }
  }
  
  # Add hostname
  mutate {
    add_field => { "hostname" => "%{host}" }
  }
}

output {
  # Output to Elasticsearch
  elasticsearch {
    hosts => ["${ELASTICSEARCH_HOST:localhost:9200}"]
    index => "agent-logs-%{+YYYY.MM.dd}"
    template_name => "agent-logs"
    template => "/etc/logstash/templates/agent-logs-template.json"
    template_overwrite => true
  }
  
  # Also output to stdout for debugging (can be removed in production)
  if "_grokparsefailure" in [tags] {
    stdout {
      codec => rubydebug
    }
  }
}

